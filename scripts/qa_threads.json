{
    "0": [
        {
            "author": "im.maddie#0000",
            "content": "what exactly is the difference between a Qm hash and a bafy hash. i know it has something to do with multihash and codec but i\u2019m not sure what\u2019s different under the hood and why"
        },
        {
            "author": "im.maddie#0000",
            "content": "and why does the local gateway prefer bafy?"
        },
        {
            "author": "Discordian#0000",
            "content": "On mobile rn, but it has to do with encoding bafy is all lowercase, and subdomains aren't case sensitive, so Qm hashes don't work so well. Also the bafy CIDs are v1 CIDs (instead of v0)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "nothing, it's just the encoding,\n`Qm` is bases 58 and thus uses a 58 alphabet for encoding, this lead to smaller more compressed keys.\n`bafy` uses a 36 alphabet (numbers + letters), `bafy` is preffered because when you are accessing `bafy.ipfs.gateway` there is no difference between upper and lower case (DNS is case incensitive, always lowering everything), and thus you couldn't encode a `Qm` hash in a host request since `Qm` differenciate `e` and `E` for example (and many other letters too)"
        },
        {
            "author": "gido5731#6422",
            "content": "can you tell your go-ipfs to always export a bafy hash?"
        },
        {
            "author": "gido5731#6422",
            "content": "or do you have to encode it manually"
        },
        {
            "author": "im.maddie#0000",
            "content": "gotcha, so it\u2019s really just encoding preference based on the situation, and is preferable for subdomains cause dns stuff\n(@Elpranocotro)"
        },
        {
            "author": "im.maddie#0000",
            "content": "thanks"
        }
    ],
    "1": [
        {
            "author": "SionoiS#5373",
            "content": "Yes working but not fully tested. @dietrich"
        },
        {
            "author": "SionoiS#5373",
            "content": "Hey guys is there no way to keep your old Peer Id when setting up a new node?"
        },
        {
            "author": "gido5731#6422",
            "content": "You can probably just copy the public and private key from the old node"
        },
        {
            "author": "gido5731#6422",
            "content": "though you presumably want to avoid running multiple nodes with the same keys"
        },
        {
            "author": "gido5731#6422",
            "content": "since that could probably cause problems"
        },
        {
            "author": "SionoiS#5373",
            "content": "with ipfs key list and ipfs key export ?"
        },
        {
            "author": "gido5731#6422",
            "content": "I mean I just go into the config file and copy the lines, then paste it into the new config"
        },
        {
            "author": "gido5731#6422",
            "content": "but that probably works"
        },
        {
            "author": "SionoiS#5373",
            "content": "ah the config that's the missing piece thanks!"
        },
        {
            "author": "gido5731#6422",
            "content": "people with ipfs seem very inclined to use commands to configure things instead of just modifying the config"
        },
        {
            "author": "gido5731#6422",
            "content": "simplest thing first imo, but if it works then whatever"
        },
        {
            "author": "SionoiS#5373",
            "content": "thank you"
        }
    ],
    "2": [
        {
            "author": "paperbenni#7715",
            "content": "if I pin an ipns adress will the pin also be updated when I update the ipns entry?"
        },
        {
            "author": "paperbenni#7715",
            "content": "As in the new hashes get pinned and the old version eventually gets garbage collected?"
        },
        {
            "author": "Discordian#0000",
            "content": "No, unfortunately such a feature doesn't exist yet\n(@paperbenni)"
        },
        {
            "author": "Discordian#0000",
            "content": "https://github.com/ipfs/go-ipfs/issues/4435"
        },
        {
            "author": "paperbenni#7715",
            "content": "hm, thanks for the info"
        }
    ],
    "3": [
        {
            "author": "dhu1337#0000",
            "content": "How to install `ipfs` on Arch Linux with latest WebUI? I installed from Arch repository but only later discovered the WebUI is out of date with no remote pin option in settings"
        },
        {
            "author": "swedneck#9241",
            "content": "you can access the latest webui at ipns://webui.ipfs.io"
        },
        {
            "author": "dhu1337#0000",
            "content": "ok thank you"
        }
    ],
    "4": [
        {
            "author": "Racin#4015",
            "content": "Dear all. I'm interested in knowing more about the storage methods in IPFS, and how content is distributed.\n\nAre you encoding the data with any error-correcting codes, e.g. Reed-Solomon?\nHow are each chunk distributed in the network?\nHow many replicas of each chunk are persisted in the network?\n\nIf anyone could point me in the right direction of documentation or code it would be greatly appreciated.\n\nThanks"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "> Are you encoding the data with any error-correcting codes, e.g. Reed-Solomon?\nNo, IPFS is wayyyy later in the layer stack, it already expect reliable transports.\nMost transport just rely on internet's corrections, but you could implement your owns corrections codes if you do an ethernet driver for example.\n\n> How are each chunk distributed in the network?\nEach node store the chunks it created, the chunk it host (pin, keep forever no matter what) and the chunks you recently downloaded. ||actually \"the chunks you added\" isn't really a category, it's just that by default add pins the files too||\n\n> How many replicas of each chunk are persisted in the network?\n0. IPFS doesn't garentee any persistancy.\nSome nodes can \"pin\" the chunks, pin mean that your node will download the chunks if not already stored, and then just keep them forever (or until the pin is removed), so if you publish your website for example, you should take care that at least 1 node pins it, you can use a service like pinata or pins them yourself (like using ipfs-cluster to manage your pins)."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "> If anyone could point me in the right direction of documentation or code it would be greatly appreciated.\nWhat do you want to know specifically, IPFS is really, huge, there are data DAGs to create files from chunks, bitswap (exchanging blocks), transports, DHT, ... ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "checkout : https://www.youtube.com/watch?v=0IGzEYixJHk this gives a really good overall first touch with the technical details"
        },
        {
            "author": "Racin#4015",
            "content": "I was just curious about if you were planning to use (or already doing) some sort of error correcting codes when storing the data.\nI was under the impression that Filecoin were going to provide ensurance of data availability."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "> I was just curious about if you were planning to use (or already doing) some sort of error correcting codes when storing the data.\nAll the chunks are addressed by their hash, so the data is already safe in that sense.\nIdk about ECC in the data, for me integrating ECC there would make no sense, because all the previous layers are already built to not fail at this task, if you get some corrupted blocks that an ECC could fix, that mean that your quic transport has a bug for example, quic should already have catched this corruption and (maybe) fixed it.\n\n> I was under the impression that Filecoin were going to provide ensurance of data availability.\nI follow filecoin from very far away.\nWhat I know on the subject still :\n- ECC for hosting files on filecoin (as means of others to fetch them), will add lots of overhead and slowness, it would probably make more sense to just store your files (like website) fully on multiple independent nodes.\n- ECC for hosting your own encrypted files makes more sense (kinda like siacoin does), from what I remember this has been discussed, from what I understand the current goal of filecoin is more to replace AWS cloudfront or cloudflare's cdn than AWS s3 specifically (comparing to AWS, but the same apply for GCP, ...)."
        },
        {
            "author": "Racin#4015",
            "content": "Sure, chunks are addressed by their chunks, however it is my understanding that IPFS uses a Merkle DAG as a data structure to organise chunks belonging to a file.\nThus to retrieve all the chunks you need to first access the root node, and then traverse down the tree to find all the leaves. If the root or any intermediate nodes are lost, you will not find the content-address of the leaves."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "> If the root or any intermediate nodes are lost, you will not find the content-address of the leaves.\nYes, this is just true.\n\nIn practice this doesn't happen that often and if this happen the whole files is on the edge to removal anyway."
        },
        {
            "author": "Racin#4015",
            "content": "I suppose there could be a hardware (or software) malfunction on the harddrive, where a small piece of data is corrupted or lost.\n\nAnyhow, what you are saying is that IPFS currently does not safeguard against such failures?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "IPFS assumes that the layers under are correctly built.\nIf your harddrive have issues and corrupt data, setup a raid.\nIf your network is corrupting packets, well the CRC in the IP stack of the kernel would catch that.\n..."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "You have a mode called hashonread that rehash all blocks when red, but it's not capable to correct anything (just detect errors).\nThis is not made to protect from harddrive issues (again a raid or FS with ECC built in would be what your need then), this is made to protect against bugs (like hard shutdown, ...) in the datastore layer (flatfs, badgerds)."
        },
        {
            "author": "Racin#4015",
            "content": "Thank you for your time!"
        }
    ],
    "5": [
        {
            "author": "ThalusA#5531",
            "content": "Hi, I don't really understand and I have a question. What is the difference between js-ipfs-http-client and js-ipfs ? I know it's written here : https://docs.ipfs.io/reference/js/api/#ipfs-and-javascript but I do not understand the response here. I don't really get if js-ipfs-http-client is for interacting with a local ipfs daemon or if js-ipfs is for creating a node in the browser and then being able to manipulate data in ipfs"
        },
        {
            "author": "Discordian#0000",
            "content": "`js-ipfs-http-client` connects to a local node, like a go-ipfs node. `js-ipfs` can spin up a node in the browser, where you have more-or-less a full node right inside the webpage."
        },
        {
            "author": "Discordian#0000",
            "content": "Also hello and welcome \ud83d\ude42"
        },
        {
            "author": "Discordian#0000",
            "content": "I'm sorry if my explanation doesn't help much with clarity, feel free to drill me with more questions if it helps."
        },
        {
            "author": "ThalusA#5531",
            "content": "by node, you mean ipfs daemon ?"
        },
        {
            "author": "Discordian#0000",
            "content": "Yes, \"local node\" would refer to your go-ipfs daemon for example."
        },
        {
            "author": "ThalusA#5531",
            "content": "So it's better to use js-ipfs since not everyone has a go-ipfs daemon running on their computer"
        },
        {
            "author": "Discordian#0000",
            "content": "Yes, absolutely. Especially if for example you'd want your application to work on a phone, that won't have a local daemon to talk to."
        },
        {
            "author": "ThalusA#5531",
            "content": "Thank you, it helped me a lot :D"
        }
    ],
    "6": [
        {
            "author": "devELIOper#4870",
            "content": "Hey is there any alternative to livepeer for doing live string on the ipfs?"
        },
        {
            "author": "devELIOper#4870",
            "content": "@dietrich"
        },
        {
            "author": "devELIOper#4870",
            "content": "Live Streaming"
        },
        {
            "author": "dietrich#1902",
            "content": "check Voodfy"
        },
        {
            "author": "dietrich#1902",
            "content": "also if you duckduckgo `ipfs live streaming` you'll find some posts and repos where people DIY'd it together"
        },
        {
            "author": "dietrich#1902",
            "content": "some nice explainers too"
        },
        {
            "author": "devELIOper#4870",
            "content": "Thanks @dietrich"
        }
    ],
    "7": [
        {
            "author": "Nycta#6816",
            "content": "greetings! how's it resonating?"
        },
        {
            "author": "Nycta#6816",
            "content": "i got lost in the links, would you please kindly direct me to where i could ask a question on api of ipfs/libp2p?"
        },
        {
            "author": "dietrich#1902",
            "content": "this is a fine place for asking generally about ipfs development, ask away! you may get more close attention in #libp2p for questions about that."
        },
        {
            "author": "Nycta#6816",
            "content": "oh thank you very much"
        }
    ],
    "8": [
        {
            "author": "stanreuben#4564",
            "content": "I want to ask a question about IPFS Cluster\n\nI'm would like to work on trustless IPFS Cluster. So the peers should not be able to get the replicated file's CID\n\nIf there's a cluster of 200 peers and the replication set to 20, and the file size is 1 mb which will be eventually broken down into multiple cids(blocks)\n\nWill that blocks be pinned in the peers as seperate blocks distributed to 200 peers or the file distributed to 20 peers as the replication min,max is 20?\n\nKindly help please"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "IPFS-Cluster isn't really meant to be used trustless (you could, and hsanjuan (the ipfs-cluster maintainer) might disagree with me on this). But most on the features just don't work trustless.\n\nThe main features work trustless by allowing a few peers. So for example, if I invite you to my cluster, I could list trusted peers (peers which are gonna make authority in the CRDT logs) so I could add / remove pins but you couldn't. (this is how https://collab.ipfscluster.io/ works).\nIdk how a replication target would work tho, idk if the untrusted peers would count toward that goal (I don't think).\nI'm really not certain but my guess is that all the \"trusted peers\" in the cluster are gonna emit that they pinned the file, but all non trusted no, so if you have let's say 30 trusted peers (which would be a lot) 20 of them might pin it, and then not all other peers. But if you have let's say 2 peers (which is more likely) I think the replication counter is gonna stay at 2, every peer is gonna think that it this is too few and peer it then.\n\nIf you are using ipfs-cluster in an trustless mode (with random peers joining your cluster), I think your only viable replication target is -1 (everyone) anyway, as you don't know if people pin files they claim pinning (which you can't check without downloading the files from their node, so you could implement a check to do that in ipfs-cluster too but at this point you are just reimplementing a filecoin like protocol inside ipfs-cluster).\n\nFor me if you want trustless decentralised pinning, you should just look at filecoin."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "\\*pinning on filecoin isn't like pinning on IPFS, pins on IPFS are free to access, pins on filecoin require the fetcher to pay a tiny fee, and their IPFS node need to be filecoin enabled"
        },
        {
            "author": "stanreuben#4564",
            "content": "So as far I understood IPFS isn't viable for trustless pinning and the files can be accessed by any peers (assuming that it will host the complete CID blocks of a particular file)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "when you say \"trustless\", how much trustless do you need ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@stanreuben is it fine if one central authority broadcast the current head target and everyone follows ?"
        },
        {
            "author": "stanreuben#4564",
            "content": "Anyway I could be able to deploy IPFS clusters on aws and can run several nodes(peers) to rplicate the files\n\nBut I was hoping to make a customized desktop software where the public can help also hosting the files as being a peer to the ipfs cluster \n\nSeemingly when scaling up we would need hypothetically thousands of terabytes \n\nThe Files will be Pictures, Videos, and other files \n \nThis is for a IPFS Powered Social media and some users will be private users so we would need to be sure that no one can access the file CID (if it reicates the distributed cid hashes to host then fine)"
        },
        {
            "author": "stanreuben#4564",
            "content": "We will be running ipfs cluster on aws, but when scaling up that would be a problem and costs will be high. So if We could make other desktop users to connect via our ipfs cluster it will be a good scaling up. But some files are hosted from Private Accounts so we would need to be careful but also need to be trustless"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "> that no one can access the file CID\nFor info, when a node download a CID it literally broadcast : \"Hey I want the block Qmfoo\" to everyone possible (they are connected too).\nAlso when you host a file the node is gonna broadcast the full CID to lots of people on the DHT.\n\nYou can't rely at all on the assumptions that the CIDs will be private. They will not.\nIf you want to do that, you need to encrypt the CID's content and share the encryption key OOB (out of band, not in the IPFS protocol)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "this could work, ipfs-cluster works fine in a mode where you have central nodes dictating what to pin.\nBut I guess you could also make your app watch the backend (blockchain, orbitdb, ... or whatever you use as backend) so this is one less centralisation point."
        },
        {
            "author": "stanreuben#4564",
            "content": "Okay is the best way is to run private data on a seperate ipfs cluster,  and Public data on a seperate cluster? where the trustless peers can host public data. That would be useful I think \n\nAlso yes the central nodes will be dictating what to pin"
        },
        {
            "author": "stanreuben#4564",
            "content": "For Backend we are building on gunDB \ud83d\ude42, thus everything is decentralized"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I'm not even talking about ipfs-cluster.\n\nI'm talking about the plain IPFS.\nIf you want to store private data, not visible to everyone on IPFS. You have 2 solutions :\n- PNET IPFS, this is a feature that allows you to create a private IPFS network (one symetric encryption key shared with all nodes), you will need your own bootstrap servers, ...\n- Encrypting your contents, this is the most simple way and allows way more granularity (as this doesn't mean that a single node have access to everyone), you can give different key to different files and give let's say one key to one guy, and an other key to an other one."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "why not have users listen the gundb database and fetch CIDs from there ? Then they aren't dictated by your own nodes."
        },
        {
            "author": "stanreuben#4564",
            "content": "You are sugessting to create the Desktop Trustless Software through gunDB?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "this wasn't already your plan ?\n\nI really know nothing about gunDB, but how were you expecting the desktop app to access the database ?"
        },
        {
            "author": "stanreuben#4564",
            "content": "For the Main Application yeah CIDs Indexed through gunDB \n\nBut for Desktop Trustless Peers to host data I haven't thought of it"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "It's just that I've understood that your app would use some kind of central server, gateway to gundb, which for me, kinda defeat the purpose (but I guess it's how everyone is using ethereum and it's working fine so ... you might be able to do this)"
        },
        {
            "author": "stanreuben#4564",
            "content": "But what I was worried about is the Private CID data stored in the devices of the trustless network and the ability to go get the cids and assessing content \n\nBut since I have cleared that making an encryption layer is better suitable for it"
        },
        {
            "author": "stanreuben#4564",
            "content": "Really Thanks for clearing me out"
        }
    ],
    "9": [
        {
            "author": "mrhavercamp#5813",
            "content": "I notice that when i'm running ipfs locally, if I browse to docs.ipfs.io it redirectly to my local node with a nice looking url docs.ipfs.io.ipns.localhost:8080. How do I achieve something similar with a directory i have pinned on my local ipfs?"
        },
        {
            "author": "AwesomeSheep48#0000",
            "content": "I believe you need to use dnslink"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "<https://dnslink.io>\n\nIt's an easy TXT record on `_dnslink.docs.ipfs.io`"
        },
        {
            "author": "Leeaandrob#9304",
            "content": "I will enter there \ud83d\ude04"
        },
        {
            "author": "mrhavercamp#5813",
            "content": "thanks @Elpranocotro reading now. we just implemented this https://developers.cloudflare.com/distributed-web/ipfs-gateway/connecting-website#connecting-to-cloudflares-gateway. is this a similar procedure?"
        },
        {
            "author": "AwesomeSheep48#0000",
            "content": "> TXT record for \\_dnslink.your.website with the value dnslink=/ipfs/\\<your\\_hash\\_here\\>\nLooks like dnslink to me"
        },
        {
            "author": "mrhavercamp#5813",
            "content": "too easy! thanks"
        }
    ],
    "10": [
        {
            "author": "FledgeShiu#8844",
            "content": "Hey guys, I'm trying to use go-ipfs in my project. However, when I second run my program, ipfs throws the error `\"no version file found, please run 0-to-1 migration tool.\"`\nHow could I set this version file?"
        },
        {
            "author": "lidel#0000",
            "content": "@FledgeShiu\\:  if you did run `ipfs init` the file should exist at `$IPFS_PATH/version`. Check if `IPFS_PATH` env variable is set to a directory with a valid IPFS repo (when missing, it defaults to `~/.ipfs`)"
        },
        {
            "author": "FledgeShiu#8844",
            "content": "@lidel Thanks for replaying. However, I'm not using the separate ipfs, instead I'm trying to use IPFS as a library. \nI followed this tutorial.\nhttps://github.com/ipfs/go-ipfs/tree/master/docs/examples/go-ipfs-as-a-library"
        },
        {
            "author": "lidel#0000",
            "content": "@FledgeShiu\\: hard to help without seeing your code, all I can say ad-hoc is\\: make sure `repoPath` is something that is persisted, that tutorial uses `createTempRepo` which will reate a new repo every time"
        },
        {
            "author": "FledgeShiu#8844",
            "content": "Thanks"
        }
    ],
    "11": [
        {
            "author": "Mauve#3354",
            "content": "Can I use DNSLink with subdomains? e.g. `ipns://example.mydomain.com`?"
        },
        {
            "author": "Discordian#0000",
            "content": "Yes\n(@Mauve)"
        },
        {
            "author": "Discordian#0000",
            "content": "Examples\\: portal.thedisco.zone chat.thedisco.zone"
        },
        {
            "author": "Mauve#3354",
            "content": "Thank you!"
        }
    ],
    "12": [
        {
            "author": "Discordian#0000",
            "content": "> Media tags don't work for audio buffers, just streaming/playing.\nI've been playing with media over IPFS in browser. Currently I can't seem to figure out how to actually get the browser to stream from IPFS. I end up having to allocate the entire thing in memory using something like `URL.createObjectURL(new Blob(content, {type: mime}));`, but I haven't figured out how to chunk it out or anything yet..."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "About the tweet, can't you just bypass this setting srcObj to an object implementing the required things ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Yes exactly (except srcObj replace createObjectURL)"
        },
        {
            "author": "Discordian#0000",
            "content": "> to an object implementing the required things\nSo you think I probably could implement a streaming concept?\n(@Elpranocotro)"
        },
        {
            "author": "Discordian#0000",
            "content": "I'm not mega familiar with these APIs, I learned them specifically to get media loading in browser from IPFS."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "All that I know is that webTorrent have an object, where you can just do `document.getElementById(\"video\").srcObj = yourWebTorrentFile` and webTorrent will respond to all the requests of the video tag in real time. If webtorrent does it, IPFS can ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Streaming the webTorrent to the video tag"
        },
        {
            "author": "Discordian#0000",
            "content": "Ah I see what probably pushed me in the direction I went in\\:> Note\\: As of March 2020, only Safari supports setting objects other than MediaStream. Until other browsers catch up, for MediaSource, Blob and File, consider falling back to creating a URL with URL.createObjectURL() and assign it to HTMLMediaElement.src. See below for an example."
        },
        {
            "author": "Discordian#0000",
            "content": "Thanks, I'm going to read into this"
        }
    ],
    "13": [
        {
            "author": "Discordian#0000",
            "content": "You're trying to index the directory over HTTP when there's an index.html I'm assuming? Hmm"
        },
        {
            "author": "Discordian#0000",
            "content": "Taking a look, the only option I see the gateway taking is a GET `filename` option... Maybe a `noindex` bool could be handy \ud83e\udd14"
        },
        {
            "author": "Chris#5446",
            "content": "Looking for collaborators https://gateway.pinata.cloud/ipfs/QmcjCygG6BZcV2LigzP7dX4qyBJnz1dRgD3KWq2AmJFzqk/"
        },
        {
            "author": "Mauve#3354",
            "content": "Ah, I thought that'd be the case. In Agregore I can pass a `?noResolve` to the querystring in a few of the protocol handlers. \ud83d\ude05"
        },
        {
            "author": "Discordian#0000",
            "content": "Sounds like a good issue for somewhere \ud83e\udd14."
        },
        {
            "author": "Mauve#3354",
            "content": "Would it be on the repo for the gateway? I'm not sure where stuff like this happens these days. \ud83d\ude1b"
        },
        {
            "author": "Discordian#0000",
            "content": "Haha I think it would be, I'm also getting acquainted with where best to file things myself \ud83d\ude05"
        },
        {
            "author": "Mauve#3354",
            "content": "\ud83e\udd37 https://github.com/ipfs/go-ipfs/issues/8265"
        },
        {
            "author": "Discordian#0000",
            "content": "Thank you so much!"
        }
    ],
    "14": [
        {
            "author": "F\u039eRB#6768",
            "content": "I see. I am still a bit confused though. Would you be willing to share explicit steps / the process how to set that up (CName and all), given: my domain is my-domain. com, I have the CID of the website folder, I want to use ipfs. io as the gateway. Thanks \ud83d\ude42"
        },
        {
            "author": "frankfka#6780",
            "content": "Is there a public node i can connect to in order to use basic queries such as `cat` using the http-client?"
        },
        {
            "author": "Discordian#0000",
            "content": "I can try, again, I haven't personally gone the CNAME route \\:').\n(@F\u039eRB)"
        },
        {
            "author": "F\u039eRB#6768",
            "content": "Oh that\u2019s fine, then how did you do it?"
        },
        {
            "author": "Discordian#0000",
            "content": "I'll write out a quick step-by-step or two when I get home \\:). Should be a about 70mins or so"
        },
        {
            "author": "SNQL#8841",
            "content": "Hi , this question likely common, is it possible to link  my Blockchain with IPFS or implement IPFS directly into a blockchain as the blockchain p2p module? In a decentralized blockchain."
        },
        {
            "author": "Discordian#0000",
            "content": "Actually it looks like I did it *very* simply, my nginx config\\:```nginx\nserver {\n        server_name portal.thedisco.zone;\n\n        listen 80;\n        listen [::]:80;\n        return https://ipfs.io/ipns/portal.thedisco.zone$request_uri;\n}\n```That's for http://portal.thedisco.zone.Then for https://chat.thedisco.zone instead I ran a go-ipfs node as well as nginx, ending up with an nginx config like this\\:```nginx\nserver {\n\tlisten 443 ssl;\n\tlisten [::]:443 ssl;\n\tserver_name chat.thedisco.zone;\n\n\tssl on;\n\tssl_certificate /etc/letsencrypt/live/chat.thedisco.zone/fullchain.pem;\n\tssl_certificate_key /etc/letsencrypt/live/chat.thedisco.zone/privkey.pem;\n\n\tlocation / {\n\t\tproxy_pass http://chat.thedisco.zone.ipns.localhost:8080;\n\t\tproxy_set_header X-Forwarded-Proto https;\n\t\tproxy_set_header X-Forwarded-For $remote_addr;\n\t}\n}\n\nserver {\n\tlisten 80 default_server;\n\tlisten [::]:80 default_server;\n\tserver_name chat.thedisco.zone;\n\n\tlocation / {\n\t\tproxy_pass http://chat.thedisco.zone.ipns.localhost:8080;\n\t\tproxy_set_header X-Forwarded-Proto http;\n\t\tproxy_set_header X-Forwarded-For $remote_addr;\n\t}\n}\n```Though I want to make it redirect HTTP to HTTPS (just haven't gotten around to it yet). Hope this helps!"
        },
        {
            "author": "Discordian#0000",
            "content": "Sorry, don't know enough about different blockchain designs to really know.\n(@SNQL)"
        },
        {
            "author": "F\u039eRB#6768",
            "content": "I see thanks! Yeah I actually store my website file on IPFS, not a server (is that what yours does?^ I'm not sure what it means by \"server {}\"). But my domain is from GoDaddy and I can edit Cname and TXT DNS files from there."
        },
        {
            "author": "Discordian#0000",
            "content": "Yeah it's on IPFS, but I have a very light VPS that redirects to ipfs.io using Nginx for the portal domain. And for the chat one I have a slightly less light VPS running a go-ipfs node (but a very light one would probably be fine too), which Nginx grabs the pages from.\n(@F\u039eRB)"
        },
        {
            "author": "F\u039eRB#6768",
            "content": "I see so you do have a self hosted node as a part of it?"
        },
        {
            "author": "Discordian#0000",
            "content": "I'll try to finagle a different solution, or hopefully someone else will interject their's."
        },
        {
            "author": "Discordian#0000",
            "content": "Yeah, I actually have one at home, and one on a VPS."
        },
        {
            "author": "Discordian#0000",
            "content": "I have the one at home peered with the one on my VPS, so it gets updates from my home node very quickly."
        },
        {
            "author": "F\u039eRB#6768",
            "content": "I see ok. Thanks for letting me know how you got yours to work! I am looking for a completely remote solution unfortunately. And would hope to use ipfs. io working as a cname gateway, or else just cloudflare"
        },
        {
            "author": "Discordian#0000",
            "content": "I'm going to get more food, but have you tried following this yet? https://docs.ipfs.io/how-to/websites-on-ipfs/link-a-domain/#domain-name-service-dns\n(@F\u039eRB)"
        },
        {
            "author": "Discordian#0000",
            "content": "Once I'm fuelled up again, if that doesn't work for you, I'll try to make it work for me"
        },
        {
            "author": "F\u039eRB#6768",
            "content": "haha yeah I just tried it, gonna give it 10 minutes for DNS to update and see!"
        },
        {
            "author": "F\u039eRB#6768",
            "content": "thank you so much! You're a huge help and so kind"
        }
    ],
    "15": [
        {
            "author": "infinite regex#4100",
            "content": "Hello, is the protocol implementation in C usable?"
        },
        {
            "author": "infinite regex#4100",
            "content": "I mean, or is Rust/Go the way to go?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "C no"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "rust is in way better shape"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "but not ready yet"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Go is the only full viable option for now"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "JS is pretty good but lacks some pretty important features (such as DHT)"
        },
        {
            "author": "infinite regex#4100",
            "content": "hmm.."
        },
        {
            "author": "infinite regex#4100",
            "content": "ok thank you \ud83d\ude04"
        }
    ],
    "16": [
        {
            "author": "Maestro#5416",
            "content": "Thank you for your answer. How to move files from ipfs pin ls to MFS?"
        },
        {
            "author": "Discordian#3926",
            "content": "That's an excellent question without a clear answer! Pins don't have human-readable names, but MFS does. So you can't easily get the filenames of your pins. However what you can do is re-add you content, get the CIDs, and then perform `ipfs files cp <cid> <MFSPath>` for each CID (as you'd know the name from the add), this should work with directories as well. There's also `ipfs files write` which might be useful to you."
        },
        {
            "author": "Maestro#5416",
            "content": "It looks simple, but I use ubuntu for 3 days and I am not programmer. I could export all cid to .txt file. How to do it automatically, I have 7000 files in my folder"
        },
        {
            "author": "Maestro#5416",
            "content": "Wait. I actually don\u2019t need file names from my cid. I just want to see list of the files in my web UI. I see file in ipfs pin ls, but no files showed in the files tab in web UI"
        },
        {
            "author": "Discordian#3926",
            "content": "Pins might be in the settings page now (I don't have mine setup, and I have to get food soon). If you don't care at all about filenames, I might be able to make you a script to copy all your pins into MFS (but they'll all just be named by their CID) if you want when I finish eats \ud83d\ude42"
        },
        {
            "author": "Discordian#3926",
            "content": "Also if you add files via the webUI, they should appear. It's only when using `ipfs add` that they won't normally, as it doesn't do the `ipfs files cp` (though `ipfs files add` is being discussed, for exactly this use-case)"
        },
        {
            "author": "Maestro#5416",
            "content": "bon apitite"
        },
        {
            "author": "Maestro#5416",
            "content": "all i have to do is add and pin file from my folder to ipfs. \n1) when i did using web ui, they just added, but not pinned. I cant pinned all at once, i have to select file, than press pin. But there are 7000+ files in my folder.\n2) when i did it using CLI, they added and pined, but i didnt see them on web ui.\n\nI need web ui, it will be comfortable for me to manage my ipfs node\n\nWhat posiable ways to solve my problem do you see?\n\nI will be appreciate for you answer"
        },
        {
            "author": "Discordian#0000",
            "content": "@Maestro\\:`ipfs_pins_to_mfs.sh`\\:```bash\n#!/bin/bash\n\n# Get pins\npins=\"$(ipfs pin ls -q --type=direct && ipfs pin ls -q --type=recursive)\"\n\n# Create `/pins` in mfs\nipfs files mkdir -p /pins\n\n# Copy every pin to MFS\nwhile read -r p; do\n  ipfs files cp /ipfs/$p /pins/$p\ndone <<< \"$pins\"\n```It'll put all your pins into an MFS dir named \"pins\""
        },
        {
            "author": "Maestro#5416",
            "content": "Thank you for your answer. But I don\u2019t know how to use it. I have to write this script into file and what next? Run it once, or every time I start the computer?"
        },
        {
            "author": "Discordian#0000",
            "content": "You need to run it every time you want to copy all your pins into your MFS, which I assumed would only be once\n(@Maestro)"
        },
        {
            "author": "Discordian#0000",
            "content": "To run it, put all that text into a file, like `ipfs_pins_to_mfs.sh` then run `chmod +x ./ipfs_pins_to_mfs.sh` on the script, then simply `./ipfs_pins_to_mfs.sh` to run it"
        },
        {
            "author": "Discordian#0000",
            "content": "The chmod step is to make it executable"
        },
        {
            "author": "Maestro#5416",
            "content": "If I will increase my folder with files, i have to run it every time. So I will run it automatically when I run a pc"
        },
        {
            "author": "Discordian#0000",
            "content": "However you're updating your folder, if you use MFS instead of pins, you won't have to copy from pins"
        },
        {
            "author": "Discordian#0000",
            "content": "But whatever works for you I suppose \\:)"
        },
        {
            "author": "Maestro#5416",
            "content": "I don\u2019t know how to use mfs, I actually don\u2019t know what is mfs"
        },
        {
            "author": "Maestro#5416",
            "content": "Thank you for your answers"
        }
    ],
    "17": [
        {
            "author": "Dietrich Ayala#0000",
            "content": "if any python folks here, a question on SO\\: https://filecoinproject.slack.com/archives/C012075EE4E/p1627485814095200"
        },
        {
            "author": "Dietrich Ayala#0000",
            "content": "https://stackoverflow.com/questions/68563079/create-ipfs-hash-of-file-in-python"
        },
        {
            "author": "Discordian#0000",
            "content": "I think they deleted it, I went to answer it earlier, but it just 404s"
        },
        {
            "author": "Dietrich Ayala#0000",
            "content": "bah"
        },
        {
            "author": "Dietrich Ayala#0000",
            "content": "thanks for checking!"
        }
    ],
    "18": [
        {
            "author": "F\u039eRB#6768",
            "content": "Hi! I'm wondering how to change my root domain to point to my ipfs address? I have a domain from GoDaddy, and the A record points to them (and is named @). There is also the main CMAKE, \"www\", pointed to @. How do I change it so the main mydomain. com points to my cloudflare gateway ipfs site?"
        },
        {
            "author": "Discordian#0000",
            "content": "I'd remove the A Record and setup a CNAME on @"
        },
        {
            "author": "F\u039eRB#6768",
            "content": "Ok thanks I will try that!"
        }
    ],
    "19": [
        {
            "author": "Anarkrypto#7179",
            "content": "there are currently hundreds of issues open.  Is it worth it ?"
        },
        {
            "author": "dietrich#1902",
            "content": "I don't know what repo you're talking about, but after working in open source for 20 yrs... YES. Always worth filing an issue. Creates that permanent record of the request, which others can +1 or comment or add to or submit a PR, etc."
        },
        {
            "author": "Discordian#0000",
            "content": "Yes absolutely worth it! The teams are very organised and just having items thought out and written down helps shape priorities!!"
        },
        {
            "author": "Anarkrypto#7179",
            "content": "Ok guys. Thanks"
        }
    ],
    "20": [
        {
            "author": "F\u039eRB#6768",
            "content": "Hey does anyone know how I could add a Python script to my website hosted on IPFS? One that can run when called upon? Or, would that require a server?\u2026"
        },
        {
            "author": "F\u039eRB#6768",
            "content": "Are there alternatives? A way to run it in browser. Or from the IPFS?"
        },
        {
            "author": "ryan__#6260",
            "content": "Depends on the code but you might try and write it in JS."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "First things, you don't \"add thing to IPFS\", you add things to a node and that node will make the file available on IPFS, if this node die and there are no other replications, the file is not accessible anymore."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@F\u039eRB you need an IPFS node to host the file long term, you can use pinata, nft.storage, self hosted, ..., then you need an environment to push files onto that node. That can be a github action runner, your browser, the same server as the long term storage node if you are self hosting it for example."
        },
        {
            "author": "F\u039eRB#6768",
            "content": "I\u2019ll see if I can in js\u2026. It\u2019s a media editor though. Like it edits photographs. Like pillow in Python."
        },
        {
            "author": "F\u039eRB#6768",
            "content": "And thank you for clarifying!"
        }
    ],
    "21": [
        {
            "author": "mrmagoo#6552",
            "content": "I have a lot of dumb questions and I'm hoping this the right place to ask? I can go back to reading the docs otherwise...\n\n1. i have setup `ipfs daemon` on my machine; when i request a file, e.g. `ipfs get XXXX` - is this file stored somewhere other than where the get command is run? i.e. is the daemon caching this or something? basically, i'm not sure i totally understand the daemon and what it's really doing \ud83d\ude42\n2. when i have a daemon setup, is this like a local gateway for ipfs? \n3. before, when i wanted to access files on ipfs, i used a public gateway and something like the ipfs python client. I was trying to access a large number of files from ipfs however, and was getting rate limited by the gateway. by using `ipfs daemon` and `ipfs get XXXX`, i guess i will not face any rate limiting, and so should be okay to download as much as I want, is that right?\n4. is there any limit to how much I can download?\n5. i may have totally misunderstood the daemon, but is it possible to only provide cache for a given list of ipfs locations, and have the daemon \"serve\" these files only? and if so, is there a local place i can find these files (i.e. without using `ipfs get` to get them)?\n\nany help is very much appreciated !"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "> 1.\nYes the file is also stored in IPFS's datastore, you can find it in `~/.ipfs/datastore` (note this will be exploded in IPFS's blocks, you can't find the file randomly there).\n> 2.\nYes, by default the local gateway is on `http://localhost:8080/ipfs/Qmfoo` or `http://localhost:8080/ipns/Qmfoo`.\n> 3.\nYour local gateway has no rate limiting, be carefull about spamming it tho, even if there is no rate limiting, IPFS isn't fast yet and it can't handle that many requests (if you spam it too much some requests will just slow down to a crawl).\n> 4.\nNo\n> 5.\nYes it's what `ipfs pin` does, lookup `ipfs pin --help`.\n\n \ud83d\ude42"
        },
        {
            "author": "mrmagoo#6552",
            "content": "ahhh so helpful! thanks so much \ud83d\ude4f"
        }
    ],
    "22": [
        {
            "author": "Yung Beef 4.0#8035",
            "content": "Hey guys, I have a question. Are IPFS node operators able to select what files they want to store? If someone uploads something bad like child porn, is it impossible to censor? Can node operators just choose not to take it and it won't be included in the network?"
        },
        {
            "author": "Yung Beef 4.0#8035",
            "content": "We're building a censorship resistant social media dApp, but are concerned about things like that getting on there."
        },
        {
            "author": "SionoiS#5373",
            "content": "You have full control of what you \"Pin\" on your node."
        },
        {
            "author": "SionoiS#5373",
            "content": "I'm building web3 social media too. Check out my stuff! github.com/sionois/dit"
        },
        {
            "author": "dietrich#1902",
            "content": "As @SionoiS said, node operators have complete control. Some operators run nginx in front of their HTTP gateway and filter out CIDs. Some run custom modules in go-ipfs itself."
        },
        {
            "author": "Yung Beef 4.0#8035",
            "content": "Awesome thanks guys"
        }
    ],
    "23": [
        {
            "author": "frankfka#6780",
            "content": "Thanks! This makes sense, but what if a client goes offline? \n\nTo persist the messages and \"replay\" to essentially catch up to the current point, would we need to have a perisistent node running that keeps a running log of all past messages?"
        },
        {
            "author": "dietrich#1902",
            "content": "that sounds more like a store-and-forward system w/ delivery guarantees, or a CRDT. i'm not sure the libp2p pubsub system does either mode, but if it does then it'd be in those docs i linked above."
        },
        {
            "author": "dietrich#1902",
            "content": "checkout OrbitDB. it's a CRDT system on top of IPFS (and libp2p) which may be closer to what you're looking for in an \"events\" system. might abstract away a lot of the complexity involved in DIYing it."
        },
        {
            "author": "frankfka#6780",
            "content": "will do! thank you"
        }
    ],
    "24": [
        {
            "author": "dtoc#8114",
            "content": "Hi all. Curious about CARs and ipfs-car. If some directory of files gets turned into a CAR and uploaded to nft.storage, could a web-app somewhere take the CID, stream and then unpack the CAR in-memory on the client-side, and show images from the CAR? Or is this mostly a cli tool for moving .cars from one place to another for like archival purposes, not streaming/app purposes?"
        },
        {
            "author": "Discordian#0000",
            "content": "Well after you have the CID, with the data added on your favourite service, you can totally stream that data in, I believe that's how CARs work. I believe CARs are just a way to make building CIDs easier, and knowing the resulting CID earlier (but I'm a bit fuzzy, I haven't actually played with CAR files myself yet)."
        },
        {
            "author": "dtoc#8114",
            "content": "Cool, will try it out. Thanks!"
        },
        {
            "author": "Discordian#0000",
            "content": "Good luck \ud83d\ude42"
        },
        {
            "author": "dtoc#8114",
            "content": "So I've been able to get some success, running into a hitch. I have this function to decar a .CAR file, IE to unpack it into a stream.\n\n`async function decar(url) {\n    const response = await got(url);\n    const files = [];\n\n    try {\n        for await (const file of unpackStream(response.body, { MemoryBlockStore })) {\n            files.push(file);\n        }\n    } catch (excp) {\n        console.log(excp);\n    } \n\n    console.log(files.length);\n}`\n\nIt throws an exception, but it partially works. Meaning I can see some of the contents of my .CAR that I uploaded in the output. Here's the error though:\n\n`TypeError: Cannot use 'in' operator to search for 'Symbol(Symbol.asyncIterator)' in :\ufffderoots\ufffd\ufffd*X%p \ufffd\ufffd\ufffd\ufffd8\ufffd\ufffd\ufffd\ufffd\u02ec\ufffd\ufffd\ufffd\ufffd\u014cCv\ufffd\ufffdTd\ufffd\ufffd\ufffd\ufffd-\ufffdgversion\ufffd\ufffdU \"\u00ee\ufffdN\ufffdrLLk8P_:M\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0649PNG`\n\nThe strange characters are part of the output. And towards the bottom, the stack trace is: \n`\nat asAsyncIterable (/Users/dtoc/Code/memex-tooling/node_modules/ipfs-car/dist/cjs/unpack/index.js:46:33)\n    at unpackStream (/Users/dtoc/Code/memex-tooling/node_modules/ipfs-car/dist/cjs/unpack/index.js:24:72)\n    at unpackStream.next (<anonymous>)\n    at decar (/Users/dtoc/Code/memex-tooling/totem.js:90:26)\n    at processTicksAndRejections (internal/process/task_queues.js:95:5)\n`\n\nThe way I know it works though, at least as far as unpacking the .CAR at least a bit, is because I can see the files I added to the .CAR in the first place, in the messed up output. See the screenshot where you can see banner.png, metadata.json, nft1.png, etc. I expect those in there, and my goal is to take the stream, unpack the .CAR in memory, and then render the pngs in some React.js. Without needing to unpack the files anywhere besides memory.\n\nEdit: interestingly enough, switching from `got` to `node-fetch` to use fetch() like in the docs gets me more of what I expect. I can see the contents of the .CAR now."
        },
        {
            "author": "dtoc#8114",
            "content": "Also, the documentation for ipfs-car mentions that there should be a IdbBlockStore. I can see that it exists, by inspecting the definition after importing it like I'm doing with the other blockstores.\n\n`const { FsBlockStore } = require('ipfs-car/blockstore/fs');\nconst { MemoryBlockStore } = require('ipfs-car/blockstore/memory');\nconst { IdbBlockStore } = require('ipfs-car/blockstore/idb');`\n\nHowever, when attempting to run the code with the IdbBlockStore import, I get this error: `Error [ERR_PACKAGE_PATH_NOT_EXPORTED]: Package subpath './blockstore/idb' is not defined by \"exports\" in /Users/dtoc/Code/memex-tooling/node_modules/ipfs-car/package.json\n`\n\nAny tips on that?\n\nEdit: Found a fix, not sure if fix or hack though. But in package.json in node_modules/ipfs-car/, there's this piece of code:\n\n`\"./blockstore/idb\": {\n      \"browser\": \"./dist/esm/blockstore/idb.js\",\n      \"import\": null,\n      \"require\": null\n    },`\n\nGetting it parity by following the piece for another one of the blockstores solved the problem. \n\n`\"./blockstore/memory\": {\n      \"browser\": \"./dist/esm/blockstore/memory.js\",\n      \"import\": \"./dist/esm/blockstore/memory.js\",\n      \"require\": \"./dist/cjs/blockstore/memory.js\"\n    }`\n\nSo it became this:\n\n`\"./blockstore/idb\": {\n      \"browser\": \"./dist/esm/blockstore/idb.js\",\n      \"import\": \"./dist/esm/blockstore/idb.js\",\n      \"require\": \"./dist/cjs/blockstore/idb.js\"\n    },`\n\nI suspect this would break when upgrading the package later on though, or if node_modules isn't part of commit history which normally you'd exclude it due to being massive..."
        },
        {
            "author": "Discordian#0000",
            "content": "I was thinking you'd just use the resulting CID, and be able to do a simple `ipfs get <cid>` on wherever you want to receive the resulting data. I might have to dive in deep to figure that one out o.o"
        },
        {
            "author": "dtoc#8114",
            "content": "Yeah that'd work from the terminal. But I'm attempting to get this streaming working, so a React app can take a .CAR, unpack it in memory (or Indexed DB if file is large), and then render the pictures/content from the files inside. Unless I'm missing something, best bet would be ipfs-car? Or is there a javascript library somewhere that lets you retrieve things easily given a CID that way? \ud83d\ude2e Because then there's no need for me to do the unpacking myself."
        },
        {
            "author": "dtoc#8114",
            "content": "Hmmm now I saw that blockstores have a .get that lets you pass in a CID and get back a Uint8Array representing the content of the .CAR file. What's not clear yet is...how I can actually extract files out of the .CAR once I've got the .CAR in memory. I'm playing around with this next: https://github.com/ipfs/js-ipfs-unixfs/blob/master/packages/ipfs-unixfs-exporter/README.md\n\nOpen to any recommendations if someone else has solved this before. I've got a .CAR available in memory, now I just want to extract my photos from it so I can pass the bytes to an image element and render a picture from a .CAR that is saved in web3.storage or nft.storage, that's my goal.\n\nEdit: ooo this is juicy https://github.com/ipld/js-car"
        },
        {
            "author": "dtoc#8114",
            "content": "Nice, thanks! Will definitely come in handy."
        }
    ],
    "25": [
        {
            "author": "Mauve#3354",
            "content": "Are there any existing \"service discovery\" type protocols on top of libp2p+ipfs?\n\nI'd wanna be able to advertise \"Hey, if you want this `service`, here's an IPNS address with my info\"."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "yes it's pretty much the \"DHT\" \ud83d\ude04"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "you can also use pubsub if you want something more high level"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@Mauve take a salt, like the name of your application, salt it with your room name (like a version, a chat room idk), hash it and put that key in the DHT (for thoses who implement it).\nThen when searching people do the same thing and search for people who claim to provide that key (just search that key, it will return you the list of people who do), assumes that all nodes providing it host your service."
        },
        {
            "author": "Mauve#3354",
            "content": "That makes sense. So is this something applications have been doing manually?"
        },
        {
            "author": "Mauve#3354",
            "content": "(like on a per project basis)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "depends, not all apps need to find services like that"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@Mauve also this means that all people hosting a service of your app are under a single key, I would try to shard that, like have people be searchable by room names, so if you assume a discord like app, I would have each guild or even room have it's own key, to avoid 3 nodes in the DHT responsible for all of your users."
        },
        {
            "author": "Mauve#3354",
            "content": "That makes sense, thank you. \ud83d\ude01"
        }
    ],
    "26": [
        {
            "author": "badassiel#7028",
            "content": "Hey, can anyone please tell me whats wrong with \n```\ncurl -X POST http://127.0.0.1:5001/api/v0/ls?arg=QmWEUMXz3ovpuHbZpagTTkBaXKWsj1uYSvVvMPqSskq3m6l\n```\nI get `{\"Message\":\"invalid path \\\"QmWEUMXz3ovpuHbZpagTTkBaXKWsj1uYSvVvMPqSskq3m6l\\\": selected encoding not supported\",\"Code\":0,\"Type\":\"error\"}` \nI get same error with arg=/ipfs/QmWEUMXz3ovpuHbZpagTTkBaXKWsj1uYSvVvMPqSskq3m6l"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "try with `arg=/ipfs/QmWEUMXz3ovpuHbZpagTTkBaXKWsj1uYSvVvMPqSskq3m6l` instead ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@badassiel ah no"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@badassiel your CID is just invalid : https://cid.ipfs.io/#QmWEUMXz3ovpuHbZpagTTkBaXKWsj1uYSvVvMPqSskq3m6l"
        },
        {
            "author": "badassiel#7028",
            "content": "That's weird. I copied it from the desktop companion's \"share link\". Is this a bug?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I have no idea, I only see that your CID is invalid, maybe you can retry re copying it ?"
        },
        {
            "author": "badassiel#7028",
            "content": "When I tried pasting it, nothing happens (I expected error message if it was invalid).\nI'm using mobile browser if that matters"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@badassiel oh no I see"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@badassiel you have an extra `l` appended"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@badassiel remove the last char and it's valid, just typo I guess"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "`QmWEUMXz3ovpuHbZpagTTkBaXKWsj1uYSvVvMPqSskq3m6` is your cid I think"
        },
        {
            "author": "badassiel#7028",
            "content": "Thank you. My bad"
        }
    ],
    "27": [
        {
            "author": "PolyMad#6344",
            "content": "hi there, new here\njust installed IPFS companion on Brave\nit works, there's traffic, but I can't find settings to limit bandwidth and disk usage\nI am on mobile network, so I can't grant much bandwidth, and I wouldn't use much either for my things"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "There is no bandwitdh limit, you can use linux's tools to do so."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "But in reality `ipfs config profile apply lowpower --dry-run` is likely way enough"
        },
        {
            "author": "PolyMad#6344",
            "content": "I'm on Win10 \ud83e\udd2d"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "**But in reality `ipfs config profile apply lowpower --dry-run` is likely way enough** \ud83d\ude42"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@PolyMad just try `lowpower` and see if that fine"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "(btw `--dry-run` will not apply anything, it's just so you see what it changes, you will need to run without it)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "also you will need to run this while the daemon is stopped or restart it after that, you can't update the config of a daemon mid flight"
        },
        {
            "author": "PolyMad#6344",
            "content": "thank you Jorr \u2764\ufe0f"
        }
    ],
    "28": [
        {
            "author": "sendmeat#5744",
            "content": "hi we're deploying a nextjs application on fleek but we're encountering some stalling, the deployment halts after the command `next start` runs. I couldn't find any resources regarding this error so wld appreciate if someone cld help us out or point us in the right direction."
        },
        {
            "author": "dietrich#1902",
            "content": "let me see if some Fleeksters can join here, or where to ask"
        },
        {
            "author": "sendmeat#5744",
            "content": "that would be nice, thank you"
        }
    ],
    "29": [
        {
            "author": "HODL#0941",
            "content": "hey gang, im noticing that opensea metadata using IPFS images is validating strangely across many NFT projects including my own which had a reveal tonight which is failing after 20 or so successful tests on rinkeby.\n\nhttps://api.opensea.io/asset/0xf6484f351e6fd323eb2e6f5f75ade92d76a155cb/24/validate/\n\nIf I validate this token many times using f5, sometimes it appears to be successful, sometimes it throws TokenUrlTimedOutException, sometimes it throws \"UnableToFetchImageException: Unable to fetch image from https://ipfs.io/ipfs/QmTJn8gmGjVFAyV2MiEWjnhRvii7ZheaGdCdg5sVKmu4WC: Unable to download image https://ipfs.io/ipfs/QmTJn8gmGjVFAyV2MiEWjnhRvii7ZheaGdCdg5sVKmu4WC due to timeout\".\n\nThis is happening with the metadata from other NFT contracts that use IFPS right now and not just mine.\n\nFor instance - Deadheads: https://api.opensea.io/asset/0x6fc355d4e0ee44b292e50878f49798ff755a5bbc/3342/validate/"
        },
        {
            "author": "HODL#0941",
            "content": "would anyone know what might be happening here? I feel like we implemented properly according to the tests we ran on test nets and what I see in metadata."
        },
        {
            "author": "HODL#0941",
            "content": "Can anyone PLEASE help me understand why sometimes my metadata is getting **tokenurltimeoutexception** and sometimes not?\n\nhttps://api.opensea.io/asset/0xf6484f351e6fd323eb2e6f5f75ade92d76a155cb/24/validate/\n\nAnd why the same thing is happening with deadheads metadata?\n\nDid this on rinkeby 20 times and never had this problem\n\nI am trying to get a project revealed for buyers and this is fucking stressful, metadata went on IPFS yesteday and this is still all fucky and people are waiting patiently for now. Any help would be greatly appreciated."
        },
        {
            "author": "dietrich#1902",
            "content": "Hey, very sorry to hear this happened during your reveal \ud83d\ude26 @dchoi27 and others are working to find a solution. The main problem is that services don't run their own IPFS nodes, and instead just all hammer the gateway, so get throttled."
        },
        {
            "author": "HODL#0941",
            "content": "its so ok!!! just hearing this is so great and clears up any uncertainty that we might have done something wrong"
        },
        {
            "author": "HODL#0941",
            "content": "thanks for the feedback"
        }
    ],
    "30": [
        {
            "author": "alph#6519",
            "content": "Hey, I'm having trouble linking my domain with my ipns..thing..."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "dnslink ?"
        },
        {
            "author": "alph#6519",
            "content": "yeah"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@alph which issue ?"
        },
        {
            "author": "alph#6519",
            "content": "\"ipfs cat /ipns/alphh.xyz/: unrecognized object type: 114\""
        },
        {
            "author": "alph#6519",
            "content": "here's my records"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Is your IPNS pointing to a valid file ?"
        },
        {
            "author": "alph#6519",
            "content": "it's pointing to my ipns node (Is it called a node?)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I mean, have you done an `ipfs name publish` at least once ?"
        },
        {
            "author": "alph#6519",
            "content": "yeah"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I'm not sure now, I'll checkout later"
        },
        {
            "author": "alph#6519",
            "content": "https://gateway.ipfs.io/ipns/k51qzi5uqu5dj3xxbfx122t01m581dkm14p8jx7glcv6vo1dw2h2aphur2e6by this works"
        },
        {
            "author": "alph#6519",
            "content": "the domain \"redirect\" doesn't"
        },
        {
            "author": "alph#6519",
            "content": "thanks"
        }
    ],
    "31": [
        {
            "author": "ZerXes#4534",
            "content": "I'm looking at building a private IPFS swarm (not for security, no one else would be interested in these files) but for speed.\nTwo of my servers will be \"bootstrap nodes\" and have ALL my files pinned, the rest of my nodes will be spread all over the globe and I will edit their bootstrap list to just bootstrap to these two nodes.\nI assume this will make my IPFS swarm only discover my own nodes or is there a additional methods that nodes can be discovered?"
        },
        {
            "author": "Discordian#0000",
            "content": "If you're using the Private Swarm features (encrypts communication between the nodes), AFAIK there's no way for you to interact with the rest of the network currently."
        },
        {
            "author": "ZerXes#4534",
            "content": "And if I don't?"
        },
        {
            "author": "Discordian#0000",
            "content": "Then certainly, no problem. You can add your nodes to your swarm lists so they stay connected, but you can bootstrap with or communicate with any other node you want to just by adding it to the bootstrap or peer list."
        },
        {
            "author": "ZerXes#4534",
            "content": "How will they discover nodes that I do not own, if none of them have another public IPFS node in the bootstrap list?"
        },
        {
            "author": "Discordian#0000",
            "content": "They won't, you'd have to add them into the bootstrap list manually (or use one of the defaults). By defaults they *might* find another node via MDNS, but I find that unlikely unless another node happens to be running on a local network and is already connected with other nodes."
        },
        {
            "author": "Discordian#0000",
            "content": "Another way they could discover nodes is if someone else discovers one of your nodes, then peers with one."
        },
        {
            "author": "ZerXes#4534",
            "content": "good \ud83d\ude42"
        },
        {
            "author": "ZerXes#4534",
            "content": "my goal here is to only have my own nodes in my swarm, I imagine it will be faster as my nodes will only search for content that will be avalible on my nodes."
        },
        {
            "author": "ZerXes#4534",
            "content": "So I assume I will just waste time querying other nodes that have 0% chance of having the content I search for"
        },
        {
            "author": "Discordian#0000",
            "content": "It certainly might be. I have a Mac on dhtclient directly peered with my desktop, and it's pretty instant for discovery. Your method should result in a tiny DHT and very little that the nodes need to do, so yeah, I'd imagine it'd be very very fast."
        },
        {
            "author": "ZerXes#4534",
            "content": "cool, thanks"
        }
    ],
    "32": [
        {
            "author": "mjcflynn#6463",
            "content": "Hi, Is there currently a way for me to use rss feeds into IPFS or something similar?  If so is there a place a can learn more?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "you can view orbit DB \"append log\" feature.\nIt's not a classical RSS feed in features, but technically I guess it's similar."
        },
        {
            "author": "mjcflynn#6463",
            "content": "Ok is there a place I can learn more about this?"
        },
        {
            "author": "mjcflynn#6463",
            "content": "If you or somebody knows of a being who can provide me with a crash course on how to add this feature I'd be willing to negotiate a fee?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "see https://orbitdb.org/"
        },
        {
            "author": "mjcflynn#6463",
            "content": "Sorry this might sound stupid.  Are you saying that once files (websites/pages) once uploaded onto OrbitDB/IPFS they can update themselves in real time.  Just as an example a News website on IPFS can update with live News feeds?"
        },
        {
            "author": "mjcflynn#6463",
            "content": "And thanks by the way"
        }
    ],
    "33": [
        {
            "author": "Discordian#0000",
            "content": "This help?```js\nconst IPFS = require('ipfs-core')\nconst fs = require('fs');\n \n async function toIPFS() {\n\t const node = await IPFS.create()\n\t const data = fs.readFileSync('./Icon.png')\n\t const results = await node.add(data, {onlyHash:true})\n\t console.log(results.cid.string)\n }\n \ntoIPFS();\n```\n(@destruction.eth)"
        },
        {
            "author": "destruction.eth#6408",
            "content": "Yes, I already solved it like that with node.addAll . Thanks!"
        },
        {
            "author": "Discordian#0000",
            "content": "Ooh thanks for showing me addAll, I hadn't looked at that, thank you as well!"
        }
    ],
    "34": [
        {
            "author": "Sluice Goose#9465",
            "content": "I have a problem with VSCode not accepting ipfs as a command. I installed the command line and everything works in powershell just fine but not in the bash terminal where i need it to work."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "You need to check that your PATH in vscode is correct and include the place where you installed IPFS."
        },
        {
            "author": "Sluice Goose#9465",
            "content": "oh shit. long day. thanks."
        }
    ],
    "35": [
        {
            "author": "Discordian#3926",
            "content": "If it was a message saying you won crypto or something, report them for spam. Also let me know, and I'll ban them from this server so they can't spam others here."
        },
        {
            "author": "Sid#9725",
            "content": "It was!"
        },
        {
            "author": "Discordian#3926",
            "content": "Thanks, taken care of on this end \ud83d\udc4d"
        }
    ],
    "36": [
        {
            "author": "idecentralize.eth#6552",
            "content": "Hello!\nWould anyone have an idea on how i can determine the type of file the hash points to?\nwhen the path ended with the extension that was easy but now it's all hashed. Is there a tool or package for this?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "wdym ?\n> that was easy but now it's all hashed\nDirectory wrapping still exists."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@idecentralize.eth look at this : https://discord.com/channels/806902334369824788/806902334369824793/890012523934412850 and the responses \ud83d\ude42 (that question was so close I thought you reposted it \ud83d\ude04)"
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "What does wdym mean?\nThank you I will look at it! Anything that return the mime-type I guess would do."
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "nvm lol"
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "what do you mean"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "What Do You Mean ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "yes"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "\ud83d\ude04"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "There is no built in mime type thing.\n\nThe real answer is just use whatever tool that will figure it out.\nIf it looks like a png it's a png likely, ..."
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "yeah image don't worry me to much it's mostly mp3/mp4 that uses diffrent html elements to be played"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "note there are many different type of files but this is a solve problem, browsers do it, ... you must find code somewhere that just find it"
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "mp3 mp4 i mean"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "an mp3 has a very distinctive header, that is trivial to see with an automated tool.\nJust search for tools that find out what files are without specifying anything about IPFS you will have way more hits."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "it's the same thing, really distinctive header for both"
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "Cool Thank you so much! I remember playing with mp3 headers in 95 haha"
        }
    ],
    "37": [
        {
            "author": "cruzz#8270",
            "content": "Hi Guys! I just started with IPFS and I am searching a good way to automate my Website deployment \ud83d\ude42\neverythin I need is:\n```\nipfs add -r ./public\nipfs name publish <CID-FROM-ADD>\n```"
        },
        {
            "author": "cruzz#8270",
            "content": "I tried using `js-ipfs` but I really don't want to create another file just for the deployment... It would be cool if I could deploy by just using a Makefile or package.json script"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "yes mostly.\nYou can do `ipfs name publish $(ipfs add -r --raw-leaves --cid-version 1 -Q ./public)` (`--raw-leaves` makes the layout a bit better for >256Kib files, `--cid-version 1` isn't actually needed, it's just future proofing yourself) to save yourself a copy paste"
        },
        {
            "author": "cruzz#8270",
            "content": "`ipfs add -r --raw-leaves --cid-version 1 ./public/` returns more then one CID .. will this still work with the `ipfs publish` command?"
        },
        {
            "author": "Serenae#5698",
            "content": "The -Q returns the one final top-level hash I think"
        },
        {
            "author": "cruzz#8270",
            "content": "oh hi @Serenae you are everywhere \ud83d\ude04 and thanks it works very well"
        }
    ],
    "38": [
        {
            "author": "OmbraRD#0780",
            "content": "Hey guys! Quick question. What's the exact format to pass to the --ignore command multiple files?"
        },
        {
            "author": "OmbraRD#0780",
            "content": "it is supposed to take an array but nothing works"
        },
        {
            "author": "OmbraRD#0780",
            "content": "With a single file, no issues. Multiple files no dice"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "You pass multiple `--ignore`\nFor example:\n```console\n$ ipfs add -r e --ignore a --ignore b\nadded QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH e/c\nadded QmXVXnAXzybxu336KuYX11TpNQhtuUB7tt38knVE7XF7E9 e\n```"
        },
        {
            "author": "OmbraRD#0780",
            "content": "i see"
        },
        {
            "author": "OmbraRD#0780",
            "content": "thanks!"
        }
    ],
    "39": [
        {
            "author": "Elpranocotro#4529",
            "content": "In theory that trivial.\n`Qm..a` is actually a folder that somewhat looks like this :\n```json\n{\n  \"link\": {\n    \"foo.txt\": \"Qm..b\",\n    \"bar.txt\": \"Qm..c\"\n  }\n}\n```\nAnd when you download `Qm..a/foo.txt` you actually walk that but I don't know if we have a neat API for this."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@jsonp you can use `ipfs ls <CID>` however that a bit ugly.\nI would like an `ipfs realpath` that follow symlinks and return me the CID of the file but I don't think we have one."
        },
        {
            "author": "jsonp#7973",
            "content": "Yeah, `realpath` would be fantastic \ud83d\ude42"
        },
        {
            "author": "jsonp#7973",
            "content": "but the solution would have to download foo.txt and hash it, correct?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Also note, doing that you must download the `Qm..a` directory obviously, and if you had `Qm..a/example/file.txt` you would download both `Qm..a` and `example`"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "no, just LS it"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@jsonp :\n```console\n$ tree t\nt\n\u2514\u2500\u2500 test.txt\n\n0 directories, 1 file\n$ ipfs add -r --pin=false t/\nadded QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH t/test.txt\nadded QmVWEMSuuRbvz1CaAEe18q7NwuASDp4XvQQnk27bRawnkr t\n$ ipfs ls QmVWEMSuuRbvz1CaAEe18q7NwuASDp4XvQQnk27bRawnkr\nQmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH 0 test.txt\n```"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "here with neat colors"
        }
    ],
    "40": [
        {
            "author": "jsonp#7973",
            "content": "What's the best way to find the CID of a child path? For example, if I have a CID with a path like `Qm..a/foo.txt`, can I find the CID of `foo.txt` without downloading the bytes and hashing them?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "In theory that trivial.\n`Qm..a` is actually a folder that somewhat looks like this :\n```json\n{\n  \"link\": {\n    \"foo.txt\": \"Qm..b\",\n    \"bar.txt\": \"Qm..c\"\n  }\n}\n```\nAnd when you download `Qm..a/foo.txt` you actually walk that but I don't know if we have a neat API for this."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@jsonp you can use `ipfs ls <CID>` however that a bit ugly.\nI would like an `ipfs realpath` that follow symlinks and return me the CID of the file but I don't think we have one."
        },
        {
            "author": "jsonp#7973",
            "content": "Yeah, `realpath` would be fantastic \ud83d\ude42"
        },
        {
            "author": "jsonp#7973",
            "content": "but the solution would have to download foo.txt and hash it, correct?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Also note, doing that you must download the `Qm..a` directory obviously, and if you had `Qm..a/example/file.txt` you would download both `Qm..a` and `example`"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "no, just LS it"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@jsonp :\n```console\n$ tree t\nt\n\u2514\u2500\u2500 test.txt\n\n0 directories, 1 file\n$ ipfs add -r --pin=false t/\nadded QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH t/test.txt\nadded QmVWEMSuuRbvz1CaAEe18q7NwuASDp4XvQQnk27bRawnkr t\n$ ipfs ls QmVWEMSuuRbvz1CaAEe18q7NwuASDp4XvQQnk27bRawnkr\nQmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH 0 test.txt\n```"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "here with neat colors"
        },
        {
            "author": "jsonp#7973",
            "content": "thanks for the example! What about if you're not adding the file yourself though? Is there a way to generate the CID for `test.txt` if you only have the links provided by `ipfs ls <parent_cid>`?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@jsonp I guess what I wanted to say is that a folder is just a \"file\" that links to other files / folders.\nSo you can download the folder, read the CID inside it but just don't follow the link."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "If you `ls` a file IPFS will download recursively all folders.\nBut it will not download the file"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@jsonp \nOn one of my servers :\n```\nroot@vps-1:/tmp# ipfs add --pin=false -r t/\nadded QmSsAozioThDDu6415QA1TiGgmJSnmohVHgph4swVDEtHf t/example\nadded Qma2Pp4gSakPCgzGZJhUj2C7JXY79HiLwQjQcJx5v95KK5 t\n 976.56 MiB / 976.56 MiB\n```\nThen on my workstation :\n```\n$ time ipfs ls Qma2Pp4gSakPCgzGZJhUj2C7JXY79HiLwQjQcJx5v95KK5\nQmSsAozioThDDu6415QA1TiGgmJSnmohVHgph4swVDEtHf 1024000000 example\n\nreal    0m0,056s\n```\nSee I was able to fetch both the CID and size of example without fetching example itself (if I were to fetch example too it would have took ~12s because I have 1Gig symetric to that server)."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "(also note the 56ms of time is because my workstation and server were already connected so it doesn't have to go search the DHT)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Basically it is as fast as my workstation broadcast : \"I'm looking for Qma2Pp4gSakPCgzGZJhUj2C7JXY79HiLwQjQcJx5v95KK5\" (the directory) and the server sending the 80 bytes of that directory."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "TL;DR when you LS a directory you download the directory block itself (which in my case is only 80 bytes) but not the files inside that directory"
        },
        {
            "author": "jsonp#7973",
            "content": "great! Thanks very much for the info!!"
        }
    ],
    "41": [
        {
            "author": "no rainbows#4854",
            "content": "Hi, can someone tell me how to query this type of url?\n`ipfs://bafyreibb2ypfrhjeikwf3tpj5ze3jh5bymrpmwlsaniet6jdeh52pxnwsq/metadata.json/`\nI want to fetch the data and use it in a front end app, but I have no idea how to \ud83d\ude26"
        },
        {
            "author": "0xatm#1724",
            "content": "either https://ipfs.io/ipfs/bafyreibb2ypfrhjeikwf3tpj5ze3jh5bymrpmwlsaniet6jdeh52pxnwsq/metadata.json or https://bafyreibb2ypfrhjeikwf3tpj5ze3jh5bymrpmwlsaniet6jdeh52pxnwsq.ipfs.dweb.link/metadata.json"
        },
        {
            "author": "no rainbows#4854",
            "content": "Thanks!!!"
        }
    ],
    "42": [
        {
            "author": "idecentralize.eth#6552",
            "content": "I think this might be a good place to ask! Anyone encrypting data before they send it to IPFS. I'am wondering how this work when the file is a streamable media. For example like Netflix does. I would like to encrypt a large media file but I would like the user to be able to start decrypting the file before it's fully downloaded."
        },
        {
            "author": "Discordian#0000",
            "content": "AES CBC mode should allow you to decrypt chunks in a stream before the full file is downloaded. Example\\: https://stackoverflow.com/a/63328319/14051077\n(@idecentralize.eth)"
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "Thank you so much for this."
        }
    ],
    "43": [
        {
            "author": "Long.L#8260",
            "content": "Hello guys."
        },
        {
            "author": "Long.L#8260",
            "content": "I have a question."
        },
        {
            "author": "Long.L#8260",
            "content": "How to use ipfs-http-client npm module in typescript?"
        },
        {
            "author": "Long.L#8260",
            "content": "Please lemme know any ideas for about that."
        },
        {
            "author": "Discordian#0000",
            "content": "The package says it supports TypeScript, is there an issue you're running into? https://www.npmjs.com/package/ipfs-http-client"
        },
        {
            "author": "Long.L#8260",
            "content": "already I have tried using it."
        },
        {
            "author": "Long.L#8260",
            "content": "it is not working on my side. \ud83d\ude26"
        },
        {
            "author": "Discordian#0000",
            "content": "Are you getting an error, or just struggling to get started in general?"
        },
        {
            "author": "Discordian#0000",
            "content": "Because if it's the latter, I will literally learn TypeScript right now, and make an example to try to help you out."
        },
        {
            "author": "Long.L#8260",
            "content": "ok, thanks. \ud83d\udc4d"
        }
    ],
    "44": [
        {
            "author": "Nufail#8463",
            "content": "Hi, I have a doubt, please help me on this. I have to perform two actions to the same (CID) file. First I should share that file to a arbitration bot to check the completeness of that file, after that I should block the free access and sell that same file to others. Is it possible in IPFS???"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Use encryption, either.\nThe easiest way is to share the file the first time OOB (**O**ut-**O**f-**B**and).\nBasically, use `ipfs dag export` to create a CAR file (an archive of ipfs blocks) and send it to your arbitration bot."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@Nufail also you could likely remove your arbitration bot using ZK proofs and make that decentralised."
        },
        {
            "author": "Nufail#8463",
            "content": "Thank you for the quick reply"
        }
    ],
    "45": [
        {
            "author": "dogada#1551",
            "content": "Hi, guys! I found very strange issue when IPFS API server blocks http-queries when User-Agent is `Mozilla` but perfectly accepts queries when user-agent is `IE` or even a random string. I filled a bug https://github.com/ipfs/go-ipfs/issues/8539 Can someone explain how it's possible at all?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "that really weird"
        },
        {
            "author": "dogada#1551",
            "content": "I actually just want to connect from Chrome to local IPFS API server but even after I disabled all CORS checking on browser side, I receive 403 error. Tried with curl and found this strange case"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@dogada that clearly a wanted feature, I've already found why, I'll respond there"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "(`rgrep Mozilla` in go-ipfs's source code tell you instantly)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@dogada hopes that clears out your question \ud83d\ude42 https://github.com/ipfs/go-ipfs/issues/8539#issuecomment-961216787"
        },
        {
            "author": "dogada#1551",
            "content": "BTW it happens also with full queries that contains Origin and Referer (I updated issue)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Really ? No it doesn't, with origin it's fine for me, do you have an example of full request failing ?"
        },
        {
            "author": "dogada#1551",
            "content": "Yep, please see my comment on the issue"
        },
        {
            "author": "dogada#1551",
            "content": "It blocks real requests that Chrome sends from localhost:3000"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "yes I've just responded about that sorry I've missed the second message"
        },
        {
            "author": "dogada#1551",
            "content": "thanks"
        }
    ],
    "46": [
        {
            "author": "Skull#8701",
            "content": "Hey hi hello! Is it possible to configure IPFS to look for files at specific IP addresses. EG if I know exactly where the files are usually already going to be can I specify a few different IP's to try *first*"
        },
        {
            "author": "Dietrich Ayala#0000",
            "content": "Skull\\: you can configure IPFS to connect to specific peers at start time with https://docs.ipfs.io/how-to/configure-node/#peering."
        },
        {
            "author": "Skull#8701",
            "content": "Perfect, thank you \ud83d\ude42"
        }
    ],
    "47": [
        {
            "author": "idecentralize.eth#6552",
            "content": "If you don't know who to Delegate to when you claim your ENS please delegate me. idecentralize.eth"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Sold for ETH already.\nElse I would have probably done it (I don't have anyone else to delegate to)."
        },
        {
            "author": "idecentralize.eth#6552",
            "content": "Ha well thanks anyways!"
        }
    ],
    "48": [
        {
            "author": "saltedlolly#5773",
            "content": "Hi all, I could really use some help. \n\nI have created an install script for setting up a DigiByte  and DigiAsset Node. DigiAssets require an IPFS server to decentralize the metadata. The problem I am having is that my install script runs as root but I need to enable the IPFS service and start it as the user.\n\nMy script successfully installs Go-IPFS using IPFS Updater. No problem there. The binary gets copied to: /usr/local/bin/ipfs\n\nIt then initialises the IPFS node in the user account with: \n\n```\n    if [ ! -d \"$USER_HOME/.ipfs\" ]; then\n        export IPFS_PATH=$USER_ACCOUNT/.ipfs\n        sudo -u $USER_ACCOUNT ipfs init\n        sudo -u $USER_ACCOUNT ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n    fi\n```\n\nNote that $USER_HOME is my variable storing the current user home folder (e.g. /home/ubuntu) and $USER_ACCOUNT stores the originating user account when running as root. (e.g. ubuntu).\n\nThis all seems to work okay so far.  When run from my 'ubuntu' user account, as root, it is successfully initialising the IPFS node in: /home/ubuntu/.ipfs\n\nSo far so good.\n\nThe problem starts when trying to create and enable/start a systemd service.\n\nBy following the instructions here, I am setting up a service to run as the user: https://github.com/ipfs/go-ipfs/tree/master/misc\n\nI would be the first to admit that I am not very knowledgeable about how systemd works."
        },
        {
            "author": "saltedlolly#5773",
            "content": "Next my script creates a ipfs.service file at: /home/ubuntu/.config/systemd/user/ipfs.service\n\nThe file contains this:\n\n```\n[Unit]\nDescription=InterPlanetary File System (IPFS) daemon\nDocumentation=https://docs.ipfs.io/\nAfter=network.target\n\n[Service]\n\n# enable for 1-1024 port listening\n#AmbientCapabilities=CAP_NET_BIND_SERVICE \n# enable to specify a custom path see docs/environment-variables.md for further documentations\n#Environment=IPFS_PATH=/custom/ipfs/path\n# enable to specify a higher limit for open files/connections\n#LimitNOFILE=1000000\n\n#don't use swap\nMemorySwapMax=0\n\n# Don't timeout on startup. Opening the IPFS repo can take a long time in some cases (e.g., when\n# badger is recovering) and migrations can delay startup.\n#\n# Ideally, we'd be a bit smarter about this but there's no good way to do that without hooking\n# systemd dependencies deeper into go-ipfs.\nTimeoutStartSec=infinity\n\nType=notify\nUser=ubuntu\nGroup=ubuntu\nStateDirectory=ipfs\nEnvironment=IPFS_PATH=/home/ubuntu/.ipfs\nExecStart=\nExecStart=/usr/local/bin/ipfs daemon --init --migrate\nRestart=on-failure\nKillSignal=SIGINT\n\n[Install]\nWantedBy=default.target\n```\n\nTHis unfortunately does not seem to work.\n\nMy next command turns on lingering for the account:\n\n`loginctl enable-linger $USER_ACCOUNT`\n\n(I assume this works. No errors produced. I don't really knwo what lingering is for but I was following the instructions.)\n\nI then try to enable the service, and this is where the problem lies. Remember everything is all running as root. I run:\n\n`systemctl --user enable ipfs`\n\nWhen I do I get this error:\n```Failed to connect to bus: $DBUS_SESSION_BUS_ADDRESS and $XDG_RUNTIME_DIR not defined (consider using --machine=<user>@.host --user to connect to bus of other user)```\n\nThe same one occurs when I try to start the service as well. \n\nCan anyone tell me what I need to do to get it to work?\n\nI have no idea what this error message means."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Sounds like you don't run systemd on your user.\nThe most simple option is just to run your ipfs service as a \"global\" deamon `/etc/systemd/system` (even if you drop IPFS's privilege like your should)."
        },
        {
            "author": "saltedlolly#5773",
            "content": "This instructions here advise running the daemon in a user session but I wasn't sure why: https://github.com/ipfs/go-ipfs/tree/master/misc"
        },
        {
            "author": "saltedlolly#5773",
            "content": "If I run as a global, can I still store the IPFS node in the user account ~/.ipfs ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@saltedlolly not really.\nWhat is important is that IPFS don't run as root (I would even just create an account for IPFS and run it seperated of your digibyte node).\nYou can run under `/home/ubuntu/.config/systemd/user/ipfs.service` or `/etc/systemd/system/ipfs.service` as long as your `.service` file contain thoses lines :\n```\nUser=ubuntu\nGroup=ubuntu\n```\nIPFS will run as whatever user you specified (here ubuntu).\n\nThe main change that `/home/ubuntu/.config/systemd/user/ipfs.service` does is that you can run IPFS without root privileges."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "But since you have root privileges just use the `/etc/systemd/system/`"
        },
        {
            "author": "saltedlolly#5773",
            "content": "Ok, thanks, I will try that. Thank you very much for your help. This has been driving me crazy!"
        },
        {
            "author": "saltedlolly#5773",
            "content": "One more thing. Do I still need to enable lingering for the user account?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@saltedlolly lingering allows unprivileged systemd services to start at boot.\n`/etc/systemd/system` is privileged and can just do whatever it wants."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "(no)"
        },
        {
            "author": "saltedlolly#5773",
            "content": "Thanks!"
        }
    ],
    "49": [
        {
            "author": "Bird#3923",
            "content": "if i have an ipfs CID can i find the directory the file is stored in?"
        },
        {
            "author": "Discordian#3926",
            "content": "No, directories store what files they contain, but files are stored unmodified (unaware of the directory they reside in)"
        },
        {
            "author": "Discordian#3926",
            "content": "(Gonna try a quick test)"
        },
        {
            "author": "Discordian#3926",
            "content": "!ipfs-check /ip4/107.179.161.187/udp/4001/quic/p2p/12D3KooWBTUkiRQXwqatERywqqF62C1cFsNYhjmXUKu3HuDafo1j QmY9cxiHqTFoWamkQVkpmmqzBrY3hCBEL2XNu3NtX74Fuu"
        },
        {
            "author": "GalaxyBot#7708",
            "content": "\u2705 Successfully connected to multiaddr\n\u2705 Found multiaddr with 10 dht peers\n\u2705 Found multihash adverised in the dht\n\u2705 The peer responded that it has the CID"
        },
        {
            "author": "Discordian#3926",
            "content": "@Elpranocotro Feel free to use this ^, it's complete now"
        },
        {
            "author": "Discordian#3926",
            "content": "!ipfs-check"
        },
        {
            "author": "GalaxyBot#7708",
            "content": "Usage: ipfs-check <multiaddr> <CID> [Backend URL]"
        },
        {
            "author": "Bird#3923",
            "content": "got it thanks"
        }
    ],
    "50": [
        {
            "author": "Garcicon#5857",
            "content": "Hi, anyone have experience with gomobile ipfs?"
        },
        {
            "author": "Garcicon#5857",
            "content": "https://tenor.com/view/simpsons-homer-bart-lisa-join-us-gif-13066208"
        },
        {
            "author": "Garcicon#5857",
            "content": "when i call the command \"make build_core.ios\" inside packages, print this message \"go.info.net.resolvConf: relocation target go.info.github.com/ipfs-shipyard/gomobile-ipfs/go/bind/core.resolverConfig not defined\""
        },
        {
            "author": "Elpranocotro#4529",
            "content": "> Quick question, is it possible to \"infer\" the parent folder in which a file is contained somehow? \nFor your case, no, you can't.\n\n> But the key is, I never share the second link anywhere, so nobody is aware of that folder name and nobody is aware that the first link is actually a package.json file in that folder.\nHave you added it to IPFS ? Because if yes then you broadcasted it to the DHT.\n\nThe issue if this is that it's the worst for everyone.\nAssuming you want to add shadow files it doesn't work because you are gonna broadcast it to the DHT.\nAssuming you want to find out who are the parrents you can't easly because it doesn't include the parrent (if it did so that would create an infinite loop where you would modify the child to include the CID of the parrent which then require you to modify the parrent to update to the new child CID, modifying the parrent cid, ...)."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Sounds like a linker / toolchain issue, update your xcode deps I guess (maybe try with `ldd` too)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@Garcicon you can also try a `go clean && make build_core.ios`"
        },
        {
            "author": "Garcicon#5857",
            "content": "thank you for your response, i already tried go clean, also i have the latest version of xcode 13.1"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Whats your `go version` ?"
        },
        {
            "author": "Garcicon#5857",
            "content": "go version go1.17.2 darwin/amd64"
        },
        {
            "author": "Garcicon#5857",
            "content": "which one do you use?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@Garcicon well I really don't know sorry.\nThat a really weird bug (sound a LOT like a toolchain bug, basically go built `go.info.net.resolvConf` but the linker can't find it).\nPlus that go std not custom code."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I'm on linux and build for android \u2764\ufe0f"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@Garcicon you can ask there https://discord.gg/SCmDDwrh (it's the team that made gomobile IPFS from go-ipfs)"
        },
        {
            "author": "Garcicon#5857",
            "content": "thank you very much for the information \ud83d\udc4d"
        }
    ],
    "51": [
        {
            "author": "searchableguy#5904",
            "content": "Hello, I was looking to build a high level hosting platform for IPFS so I was wondering if there were any cheap ipfs hosting service I could use to build the infra on."
        },
        {
            "author": "searchableguy#5904",
            "content": "Pinata is a bit too expensive."
        },
        {
            "author": "searchableguy#5904",
            "content": "I would prefer if it was open source."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "https://web3.storage, https://estuary.tech both open source, estuary is self hostable, web3.storage I guess so since it's open source, I don't know how easy is it.\n\nInstead of you having to pay, I would consider just adding support for many different pinning API and let user use their own key (idealy pinata or web3.storage would just support SSO, I've heard that it's planned for web3.storage, idk about pinata).\nSo your users pay not you (your app then become a pin manager more than anything else I guess, but there is still lots you can do to make managing pins easier than the current web3.storage or pinata interfaces)."
        },
        {
            "author": "searchableguy#5904",
            "content": "What is the catch for web3 storage? I don't see any pricing."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "there is none, it's sponsorised by protocol labs."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@searchableguy the filecoin storage is actually free because it's Fil+ validation power, the IPFS and servers is sponsorised"
        },
        {
            "author": "searchableguy#5904",
            "content": "Could someone build a service on top of it and sell it?"
        },
        {
            "author": "searchableguy#5904",
            "content": "Because without pricing, that seems risky"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "depends, I don't think so"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "@searchableguy 1Tib is gonna run fast"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "(in your case)"
        },
        {
            "author": "searchableguy#5904",
            "content": "I might need to look into self hosting it."
        },
        {
            "author": "searchableguy#5904",
            "content": "It said you could ask for increase"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I don't know how they allow this, but I don't think they would accept if you just ressel it after.\n\nIf I would manage that I would try to approve things that profits everyone (imagine a service that hosts DeFi apps for example)"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I don't know their policy but I don't think if you just ressel web3.storage with a good UX they are gonna give you that many storage"
        },
        {
            "author": "searchableguy#5904",
            "content": "Yup. I plan to build high level services on top but still would prefer to pay for the usage and not worry about anything. I just want something managed which I can use for the core infrastructure."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I belive your cheapest option is gonna be self hosting, either using ipfs-cluster, a custom solution or estuary.tech (self hosting it)"
        },
        {
            "author": "searchableguy#5904",
            "content": "Thanks for the answer."
        }
    ],
    "52": [
        {
            "author": "MrHeviDi#8929",
            "content": "hi, Im running IPFS desktop \ud83d\ude09 ..it was just for geting CID to mint NFT on ZKSync"
        },
        {
            "author": "MrHeviDi#8929",
            "content": "but my question is...  if I turn off IPFS I will not be able to check this NFT? I need to run whole day IPFS?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "yes you do.\nHowever it doesn't need to be your node.\n\nAny different node hosting your file will share it to require people.\n\nCheckout https://nft.storage/ it's a free pinning service that host your NFTs for you."
        },
        {
            "author": "MrHeviDi#8929",
            "content": "hmmm thanks"
        }
    ],
    "53": [
        {
            "author": "enriqueesanchz#6582",
            "content": "how do I completely uninstall IPFS? I built it from sources"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "`rm $(which ipfs)` will remove the binary (might need to sudo it)\n`rm -rf ~/.ipfs/` will remove your local datas (such as config, datastore, ...)"
        },
        {
            "author": "enriqueesanchz#6582",
            "content": "thank you"
        }
    ],
    "54": [
        {
            "author": "tedsteen#5508",
            "content": "Hey! So I'm using the rust implementation of libp2p kademlia as a way to do p2p signaling. This works well locally as the nodes are found through mDNS but now I'd like to take it outside of my network and need to bootstrap the network somehow.\n\nAre there any public and usable nodes I can use? Or how are these things done generally?"
        },
        {
            "author": "tedsteen#5508",
            "content": "My initial goal was to be 100% serverless and leech on some existing p2p network \ud83d\ude07"
        },
        {
            "author": "tedsteen#5508",
            "content": "I'm using this: https://github.com/libp2p/rust-libp2p/blob/master/examples/distributed-key-value-store.rs"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "any libp2p node running DHT is usable.\nJust use the IPFS bootstrap one (actually I belive you should pick 50 random nodes from the IPFS network instead to avoid over relaying on 4 nodes)"
        },
        {
            "author": "tedsteen#5508",
            "content": "fantastic thank you! I will try this"
        }
    ],
    "55": [
        {
            "author": "Signainu#1552",
            "content": "so i got ipfs working for one cid working for my website hockeycards.eth but the cid I am using for footballcards.eth does not want to load. Any help?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "whats the CID ?"
        },
        {
            "author": "Signainu#1552",
            "content": "actually it does work in brave but does work in chrome QmR6awqvxE1E4WfcT9Cax9MwQj41eM65gkoVKJDbdkUFsE"
        },
        {
            "author": "Signainu#1552",
            "content": "sorry i think its working i keep forgetting to add the / at the end"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "chrome doesn't have IPFS support, what are you actually using ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "!ipfs-stat QmR6awqvxE1E4WfcT9Cax9MwQj41eM65gkoVKJDbdkUFsE"
        },
        {
            "author": "GalaxyBot#7708",
            "content": "Trying to stat QmR6awqvxE1E4WfcT9Cax9MwQj41eM65gkoVKJDbdkUFsE (up to 30s)"
        },
        {
            "author": "GalaxyBot#7708",
            "content": "Successfully retrieved QmR6awqvxE1E4WfcT9Cax9MwQj41eM65gkoVKJDbdkUFsE."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Well the file seems to be accessible"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "I guess that an issue with what you are using with chrome"
        },
        {
            "author": "Signainu#1552",
            "content": "thank you for the assistance"
        }
    ],
    "56": [
        {
            "author": "ATLowther#8763",
            "content": "I am trying to create a CID manually. Ie go through all of the steps from the hash to having the CID. I've read the documentation but it's unclear to me how to get from the starting hash to the ending CID. Could anybody help point me in the right direction? If I have a starting SHA-256 hash, where do I go from there?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "What do you want ? I mean you have a file and want to manually CID ify it ?"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "The most simple way is to get a file that is smaller than 1Mib, just hash it and put the hash into a CIDv1 raw leaf.\nBasically if you do a raw leaf the file it self become it's own block.\nIf you don't you would need to serialise it into cbor or pb."
        },
        {
            "author": "ATLowther#8763",
            "content": "Yes, exactly"
        },
        {
            "author": "ATLowther#8763",
            "content": "I'm just looking to understand the process, step-by-step. Taking a hash of a file and knowing how to get to its correspoding CIDv0"
        },
        {
            "author": "Elpranocotro#4529",
            "content": "CIDv0 is pb encoded so it's non trivial"
        },
        {
            "author": "ATLowther#8763",
            "content": "What is that? When I Google it I've found a few things: Protocol Buffers, Permutative encoding."
        },
        {
            "author": "Elpranocotro#4529",
            "content": "Protocol Buffers sorry"
        },
        {
            "author": "Discordian#0000",
            "content": "Perhaps this will help? https://proto.school/anatomy-of-a-cid\n(@ATLowther)"
        },
        {
            "author": "ATLowther#8763",
            "content": "I've taken this course before, actually! Looking back over it, I seem to be doing something wrong and I don't know what it is. Many parts of the CID are just pieces of metadata, so I can just prepend those. But, given a hash value, how could I take that and build a CIDv0. My understanding is that it would look, in parts, `Qm`(Identifier for CIDv0  `0x12`(Sha2-256) `0x20`(Length, in bytes of the SHA2-256 HASH) `${HASH_VALUE}`.\n\nSo my CIDv0 would then be `Qm(base58btc(1220${HASH_VALUE})`, but when I do that I seem to be getting an invalid CID, so I am not sure what i might be doing wrong."
        },
        {
            "author": "Discordian#3926",
            "content": "Hmm I think #ipld would be a great place to ask that tbh. It sounds like you're trying to A-Z take a file, and get a CID from that, so maybe we need a guide to that effect. But in that channel you'll have a lot of experts on IPLD structures, and you'll probably get a specific answer in there."
        },
        {
            "author": "ATLowther#8763",
            "content": "Thank you \ud83d\ude4f"
        }
    ]
}